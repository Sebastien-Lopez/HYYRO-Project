{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sebas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, GRU, Embedding, Dropout, MaxPooling1D, Conv1D, AveragePooling1D, Flatten,Bidirectional,BatchNormalization, LSTM, SpatialDropout1D\n",
    "from keras.initializers import TruncatedNormal\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def removeStopWords_Lemmatize(s):\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(s)\n",
    "    tempList = [token.lower() for token in tokens if token.lower() not in stopset and  len(token)>2]\n",
    "    tempList = [lemmatizer.lemmatize(w) for w in tempList]\n",
    "    return \" \".join(x for x in tempList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_lengthening(text):\n",
    "\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ad Link</th>\n",
       "      <th>Category</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Maple dining table with chairs (matching Side ...</td>\n",
       "      <td>Beautiful Solid Queensland fiddleback maple di...</td>\n",
       "      <td>$800 negotiable</td>\n",
       "      <td>Bayside Area, Brighton</td>\n",
       "      <td>/s-ad/brighton/antiques/maple-dining-table-wit...</td>\n",
       "      <td>antiques-art-collectables</td>\n",
       "      <td>-37.9081962</td>\n",
       "      <td>144.9957991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Art Deco painting (from original).</td>\n",
       "      <td>Art Deco painting on board with frame from ori...</td>\n",
       "      <td>$600</td>\n",
       "      <td>Glen Eira Area, Bentleigh</td>\n",
       "      <td>/s-ad/bentleigh/art/art-deco-painting-from-ori...</td>\n",
       "      <td>antiques-art-collectables</td>\n",
       "      <td>-37.9185101</td>\n",
       "      <td>145.0409246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0  Maple dining table with chairs (matching Side ...   \n",
       "1           1                 Art Deco painting (from original).   \n",
       "\n",
       "                                         Description             Price  \\\n",
       "0  Beautiful Solid Queensland fiddleback maple di...   $800 negotiable   \n",
       "1  Art Deco painting on board with frame from ori...             $600    \n",
       "\n",
       "                     Location  \\\n",
       "0      Bayside Area, Brighton   \n",
       "1   Glen Eira Area, Bentleigh   \n",
       "\n",
       "                                             Ad Link  \\\n",
       "0  /s-ad/brighton/antiques/maple-dining-table-wit...   \n",
       "1  /s-ad/bentleigh/art/art-deco-painting-from-ori...   \n",
       "\n",
       "                    Category     Latitude    Longitude  \n",
       "0  antiques-art-collectables  -37.9081962  144.9957991  \n",
       "1  antiques-art-collectables  -37.9185101  145.0409246  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"gumtree Scrapping data.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the null values with some self-explanotory text\n",
    "data[\"Description\"]=data[\"Description\"].fillna(\"Undescribed\")\n",
    "data[\"Price\"]=data[\"Price\"].fillna(\"Unpriced\")\n",
    "\n",
    "# filter out for non characters\n",
    "data[\"Title\"]=data[\"Title\"].apply(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "data[\"Description\"]=data[\"Description\"].apply(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "data[\"Price\"]=data[\"Price\"].apply(lambda x: re.sub(r'\\W+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "banned = ['and', 'to', 'the', 'a', 'for','with', 'in','is', 'of', 'or', 'on', 'you', 'are', 'from', 'up', 'available'\n",
    "               ,'The', 'Have', 'all', 'at', 'as', 'condition' , 's', 'I', 'your', 'can',  'our', 'new',\n",
    "                'it', 'be', 'We','x', 'This','has','will','only','this', 'New', 'pick','my','an''very', 'if',\n",
    "               'Please', 'also','more','no', 'but', 'Size', 'Melbourne', 'been', 'A', '7', 'store', 'Brand', 'sale', 'any'\n",
    "               ,'great','It', 'well', 'price','All', 'us', 'me', 'so', 'just', 'Australia', 't', 'Hey', \"i'm\", 'hey','hi'\n",
    "         , 'Hi',\"Iâ€™m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: ' '.join([item for item in x.split() if item not in banned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Maple dining table chairs matching Side Board ...\n",
       "1       Art Deco painting original Art Deco painting b...\n",
       "2       Art Deco painting canvas Art Deco painting can...\n",
       "3       Horse Racing Memorabilia Black Caviar Black ca...\n",
       "4       Pokemon Cards Wanted Cash Paid Same Day Pickup...\n",
       "                              ...                        \n",
       "2402    BMX STYLE BIKE got BMX style bike 20 Weels col...\n",
       "2403    Everlast Precision Leather Double Ended Strike...\n",
       "2404    Mag Bike Dual Purpose Bodyworx ADPE 8 Levels R...\n",
       "2405    UNDER ARMOUR mens compression shorts M NEW WIT...\n",
       "2406    Everlast Adjustable Speedball Platform In Box ...\n",
       "Name: X, Length: 2407, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatinate the Title, Description and Price column\n",
    "data[\"X\"]= data[\"Title\"].apply(str)+\" \"+data[\"Description\"].apply(str)+\" \"+data[\"Price\"].apply(str)\n",
    "\n",
    "#Remove banned words words\n",
    "data[\"X\"] = data[\"X\"].astype(str).apply(f)\n",
    "\n",
    "#Remove Stop words\n",
    "\n",
    "data[\"X\"]=data[\"X\"].apply(lambda x: removeStopWords_Lemmatize(x))\n",
    "\n",
    "#Fix the extra letters like Yesssss\n",
    "data[\"X\"]= data[\"X\"].apply(lambda x: reduce_lengthening(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[\"X\"]\n",
    "targets= data[\"Category\"].values\n",
    "#targets = targets.reshape((len(targets), 1))\n",
    "\n",
    "tokenizer = Tokenizer( filters='!\"#$%&()*+,-./:;<=>@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
    "\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= tts(x,targets,test_size=0.2, random_state=4)\n",
    "\n",
    "x_tr=tokenizer.texts_to_sequences(x_train)\n",
    "x_ts=tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_tr=pad_sequences(x_tr, maxlen=250)\n",
    "x_ts=pad_sequences(x_ts, maxlen=250)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    y_test_enc = np_utils.to_categorical(y_test_enc)\n",
    "    y_train_enc = np_utils.to_categorical(y_train_enc)\n",
    "    return y_train_enc, y_test_enc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test=prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=vocab_size, output_dim= embedding_dim, input_length=250, embeddings_initializer='TruncatedNormal'))\n",
    "model2.add(Conv1D(200, kernel_size=10,strides=1,activation='relu' ))\n",
    "model2.add(AveragePooling1D(pool_size=8, strides=None, padding='same'))\n",
    "model2.add(MaxPooling1D(pool_size=5, strides=None, padding='same'))\n",
    "model2.add(GRU(256, recurrent_dropout=0.3))\n",
    "#model2.add(Dropout(0.2))\n",
    "model2.add(Dense(12, activation='softmax'))\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model2.summary()\n",
    "\n",
    "\n",
    "\n",
    "model2.fit(x_tr, y_train,epochs=5,verbose=1,batch_size=32)\n",
    "\n",
    "_, val_acc2 = model2.evaluate(x_ts, y_test, verbose=0)\n",
    "print('validation_accuracy is: ', val_acc2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
